{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiobooks using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "A machine learning algorithm based on available data that can predict if a customer will buy again from the Audiobook company.\n",
    "\n",
    " \n",
    "There are several variables: Customer ID, Book length in mins_avg (average of all purchases), Book length in minutes_sum (sum of all purchases), Price Paid_avg (average of all purchases), Price paid_sum (sum of all purchases), Review (a Boolean variable), Review (out of 10), Total minutes listened, Completion (from 0 to 1), Support requests (number), and Last visited minus purchase date (in days).\n",
    "\n",
    "The targets are a Boolean variable (so 0, or 1). \n",
    "\n",
    "This is a classification problem with two classes: won't buy and will buy, represented by 0s and 1s. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Book length (mins)_overall</th>\n",
       "      <th>Book length (mins)_avg</th>\n",
       "      <th>Price_overall</th>\n",
       "      <th>Price_avg</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review 10/10</th>\n",
       "      <th>Completion</th>\n",
       "      <th>Minutes listened</th>\n",
       "      <th>Support Requests</th>\n",
       "      <th>Last visited minus Purchase date</th>\n",
       "      <th>Targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16772.491551</td>\n",
       "      <td>1591.281685</td>\n",
       "      <td>1678.608634</td>\n",
       "      <td>7.103791</td>\n",
       "      <td>7.543805</td>\n",
       "      <td>0.160750</td>\n",
       "      <td>8.909795</td>\n",
       "      <td>0.125659</td>\n",
       "      <td>189.888983</td>\n",
       "      <td>0.070222</td>\n",
       "      <td>61.935033</td>\n",
       "      <td>0.158833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9691.807248</td>\n",
       "      <td>504.340663</td>\n",
       "      <td>654.838599</td>\n",
       "      <td>4.931673</td>\n",
       "      <td>5.560129</td>\n",
       "      <td>0.367313</td>\n",
       "      <td>0.643406</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>371.084010</td>\n",
       "      <td>0.472157</td>\n",
       "      <td>88.207634</td>\n",
       "      <td>0.365533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8368.000000</td>\n",
       "      <td>1188.000000</td>\n",
       "      <td>1188.000000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16711.500000</td>\n",
       "      <td>1620.000000</td>\n",
       "      <td>1620.000000</td>\n",
       "      <td>5.950000</td>\n",
       "      <td>6.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25187.250000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.910000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33683.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>130.940000</td>\n",
       "      <td>130.940000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  Book length (mins)_overall  Book length (mins)_avg  \\\n",
       "count  14084.000000                14084.000000            14084.000000   \n",
       "mean   16772.491551                 1591.281685             1678.608634   \n",
       "std     9691.807248                  504.340663              654.838599   \n",
       "min        2.000000                  216.000000              216.000000   \n",
       "25%     8368.000000                 1188.000000             1188.000000   \n",
       "50%    16711.500000                 1620.000000             1620.000000   \n",
       "75%    25187.250000                 2160.000000             2160.000000   \n",
       "max    33683.000000                 2160.000000             7020.000000   \n",
       "\n",
       "       Price_overall     Price_avg        Review  Review 10/10    Completion  \\\n",
       "count   14084.000000  14084.000000  14084.000000  14084.000000  14084.000000   \n",
       "mean        7.103791      7.543805      0.160750      8.909795      0.125659   \n",
       "std         4.931673      5.560129      0.367313      0.643406      0.241206   \n",
       "min         3.860000      3.860000      0.000000      1.000000      0.000000   \n",
       "25%         5.330000      5.330000      0.000000      8.910000      0.000000   \n",
       "50%         5.950000      6.070000      0.000000      8.910000      0.000000   \n",
       "75%         8.000000      8.000000      0.000000      8.910000      0.130000   \n",
       "max       130.940000    130.940000      1.000000     10.000000      1.000000   \n",
       "\n",
       "       Minutes listened  Support Requests  Last visited minus Purchase date  \\\n",
       "count      14084.000000      14084.000000                      14084.000000   \n",
       "mean         189.888983          0.070222                         61.935033   \n",
       "std          371.084010          0.472157                         88.207634   \n",
       "min            0.000000          0.000000                          0.000000   \n",
       "25%            0.000000          0.000000                          0.000000   \n",
       "50%            0.000000          0.000000                         11.000000   \n",
       "75%          194.400000          0.000000                        105.000000   \n",
       "max         2160.000000         30.000000                        464.000000   \n",
       "\n",
       "            Targets  \n",
       "count  14084.000000  \n",
       "mean       0.158833  \n",
       "std        0.365533  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Audiobooks_data.csv\")\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:11].values  #remove IDs\n",
    "y = df.iloc[:,11:12].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of y's = 0 shall be equal to Number of y's = 1\n",
    "num_one_y = int(np.sum(y))\n",
    "\n",
    "\n",
    "zero_y_counter = 0\n",
    "\n",
    "indices_to_remove = []\n",
    "\n",
    "for i in range(y.shape[0]):\n",
    "    if y[i] == 0:\n",
    "        zero_y_counter += 1\n",
    "        if zero_y_counter > num_one_y:\n",
    "            indices_to_remove.append(i)\n",
    "\n",
    "X = np.delete(X,indices_to_remove, axis = 0)\n",
    "y = np.delete(y, indices_to_remove, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize X (inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the shuffled data into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=1, shuffle= True)\n",
    "\n",
    "# Split train again to train and validation # 0.125 x 0.8 = 0.1\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1, shuffle= True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the three datasets in *.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Audiobooks_data_train', inputs=X_train, targets=y_train)\n",
    "np.savez('Audiobooks_data_validation', inputs=X_val, targets=y_val)\n",
    "np.savez('Audiobooks_data_test', inputs=X_test, targets=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "train_inputs, train_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Outline, optimizers, loss, early stopping and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 - 0s - loss: 0.5428 - accuracy: 0.7198 - val_loss: 0.4444 - val_accuracy: 0.7837\n",
      "Epoch 2/100\n",
      "71/71 - 0s - loss: 0.4116 - accuracy: 0.7859 - val_loss: 0.3984 - val_accuracy: 0.7817\n",
      "Epoch 3/100\n",
      "71/71 - 0s - loss: 0.3784 - accuracy: 0.7984 - val_loss: 0.3837 - val_accuracy: 0.7937\n",
      "Epoch 4/100\n",
      "71/71 - 0s - loss: 0.3631 - accuracy: 0.8072 - val_loss: 0.3741 - val_accuracy: 0.7897\n",
      "Epoch 5/100\n",
      "71/71 - 0s - loss: 0.3565 - accuracy: 0.8061 - val_loss: 0.3687 - val_accuracy: 0.7877\n",
      "Epoch 6/100\n",
      "71/71 - 0s - loss: 0.3519 - accuracy: 0.8066 - val_loss: 0.3638 - val_accuracy: 0.7976\n",
      "Epoch 7/100\n",
      "71/71 - 0s - loss: 0.3448 - accuracy: 0.8146 - val_loss: 0.3648 - val_accuracy: 0.7956\n",
      "Epoch 8/100\n",
      "71/71 - 0s - loss: 0.3397 - accuracy: 0.8143 - val_loss: 0.3671 - val_accuracy: 0.8036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f47740f2070>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_size = 10\n",
    "output_size = 2\n",
    "\n",
    "hidden_layer_size = 50\n",
    "    \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(hidden_layer_size, activation='relu'), \n",
    "            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "            tf.keras.layers.Dense(output_size, activation='softmax') \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "### Training\n",
    "\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "# set an early stopping mechanism\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(train_inputs, \n",
    "          train_targets, \n",
    "          batch_size=batch_size, \n",
    "          epochs=max_epochs, \n",
    "          callbacks=[early_stopping], \n",
    "          validation_data=(validation_inputs, validation_targets), \n",
    "          verbose = 2 \n",
    "          )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 852us/step - loss: 0.3156 - accuracy: 0.8281\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.32. Test accuracy: 82.81%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
